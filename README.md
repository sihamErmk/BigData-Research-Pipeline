# Research Article Scraper

Scrapy-based web scraper for collecting academic articles from multiple sources.

## ğŸ“Š Data Sources

| Source | Status | Articles/Keyword | Notes |
|--------|--------|------------------|-------|
| **arXiv** | âœ… Working | 50 | API-based, no CAPTCHA |
| **IEEE** | âœ… Working | 250 (10 pages) | Selenium required |
| **Google Scholar** | âš ï¸ Limited | 20 | May trigger CAPTCHA |
| **ACM** | âŒ Blocked | - | Cloudflare protection |
| **ScienceDirect** | âŒ Blocked | - | Cloudflare protection |

## ğŸš€ Quick Start

### Prerequisites
```bash
pip install scrapy pymongo selenium webdriver-manager
```

### MongoDB Setup
```bash
# Start MongoDB
mongod

# Verify connection
mongosh
use research_db
```

### Run Scrapers
```bash
# Best option - arXiv (no CAPTCHA)
python -m scrapy crawl arxiv

# IEEE (with pagination)
python -m scrapy crawl ieee

# Google Scholar (use sparingly)
python -m scrapy crawl scholar
```

## ğŸ“ Project Structure
```
Data scraper/
â”œâ”€â”€ spiders/
â”‚   â”œâ”€â”€ arxiv_spider.py          # âœ… Recommended
â”‚   â”œâ”€â”€ ieee_spider.py           # âœ… Works well
â”‚   â”œâ”€â”€ scholar_spider.py        # âš ï¸ CAPTCHA risk
â”‚   â”œâ”€â”€ acm_spider.py            # âŒ Blocked
â”‚   â””â”€â”€ sciencedirect_spider.py  # âŒ Blocked
â”œâ”€â”€ items.py                     # Data structure
â”œâ”€â”€ pipelines.py                 # MongoDB pipeline
â”œâ”€â”€ selenium_middleware.py       # Browser automation
â”œâ”€â”€ settings.py                  # Scrapy config
â””â”€â”€ scrapy.cfg
```

## ğŸ”§ Configuration

### Keywords
Edit keywords in each spider file:
```python
keywords = ['Machine Learning', 'Deep Learning', 'AI']
```

### MongoDB
Edit in `settings.py`:
```python
MONGO_URI = 'mongodb://localhost:27017/'
MONGO_DATABASE = 'research_db'
```

## ğŸ“ˆ Expected Results

- **arXiv**: ~1,500 articles (30 keywords Ã— 50)
- **IEEE**: ~2,250 articles (9 keywords Ã— 250)
- **Scholar**: ~500 articles (25 keywords Ã— 20)
- **Total**: ~4,250 articles

## ğŸ›¡ï¸ Anti-Detection

- Random delays between requests
- Selenium with anti-detection scripts
- Cookie acceptance automation
- Human-like scrolling behavior

## ğŸ“Š View Data

```bash
# MongoDB Shell
mongosh
use research_db
db.articles.countDocuments()
db.articles.find().limit(5)

# Export to JSON
mongoexport --db=research_db --collection=articles --out=articles.json

# Export to CSV
mongoexport --db=research_db --collection=articles --type=csv --fields=titre,auteurs,annee,source --out=articles.csv

# Or use the Python script
python export_to_csv.py
```

## ğŸ§¹ Data Cleaning

After scraping, clean and analyze your data using our Kaggle notebook:

**[ğŸ““ Data Processing Notebook](https://www.kaggle.com/code/errrrr13ee/data-processing)**

The notebook includes:
- Data cleaning and preprocessing
- Duplicate removal
- Missing value handling
- Exploratory data analysis
- Visualizations

## âš ï¸ Important Notes

1. **Use arXiv as primary source** - Most reliable, no CAPTCHA
2. **IEEE requires Selenium** - Browser will open automatically
3. **Respect rate limits** - Don't scrape too aggressively
4. **ACM/ScienceDirect blocked** - Use their official APIs instead
5. **Duplicates handled** - MongoDB unique index on `lien` field

## ğŸ› Troubleshooting

### CAPTCHA Issues
- Increase `DOWNLOAD_DELAY` in settings.py
- Use `SELENIUM_HEADLESS = False` to solve manually
- Switch to arXiv (no CAPTCHA)

### MongoDB Connection Error
```bash
# Check if MongoDB is running
mongosh --eval "db.version()"
```

### Selenium ChromeDriver Issues
```bash
# Reinstall webdriver-manager
pip install --upgrade webdriver-manager
```

# BigData Research Pipeline - Dashboard BI et Analyses AvancÃ©es

Ce projet est une application de Business Intelligence dÃ©veloppÃ©e avec Streamlit. Elle permet d'explorer, de filtrer et d'analyser des donnÃ©es issues de publications scientifiques stockÃ©es dans une base de donnÃ©es MongoDB.

## FonctionnalitÃ©s principales

### Dashboard BI
- Indicateurs clÃ©s (KPI) : Publications, AnnÃ©e Moyenne, nombre d'Auteurs et taux d'Abstracts.
- RÃ©partition par Source : Visualisation des parts de marchÃ© des diffÃ©rentes plateformes.
- Top 10 Mots-clÃ©s : Les thÃ©matiques les plus populaires dans la recherche.
- Ã‰volution Temporelle : Analyse du volume de publications par annÃ©e.

### Analyses AvancÃ©es
- Analyse par Domaine : Exploration dÃ©taillÃ©e par mot-clÃ© (Data Mining, AI, Deep Learning).
- Collaborations Scientifiques : Identification des auteurs et partenariats les plus actifs.

## AperÃ§u du Dashboard

### Statistiques Globales
![alt text](Dashboard_BI/chart1.png)
*RÃ©partition des articles par source.*

![alt text](Dashboard_BI/chart2.png)
*Les 10 mots-clÃ©s les plus frÃ©quents.*

![alt text](Dashboard_BI/chart3.png)
*Progression historique des publications.*

### Analyses SpÃ©cifiques par Domaine
![alt text](Dashboard_BI/chart5.png)
*Focus sur l'Ã©volution du Data Mining.*

![alt text](Dashboard_BI/chart6.png)
*Focus sur l'Ã©volution de l'Intelligence Artificielle.*

![alt text](Dashboard_BI/chart7.png)
*Focus sur l'Ã©volution du Deep Learning.*

### Collaborations et Auteurs
![alt text](Dashboard_BI/chart4.png)
*Classement des auteurs les plus prolifiques.*

## Technologies utilisÃ©es

- Python (Streamlit, Pandas, Plotly)
- MongoDB (Base de donnÃ©es NoSQL)
- PyMongo (Driver de connexion)

## Installation

1. Assurez-vous d'avoir MongoDB installÃ© et configurÃ©.
2. Installez les dÃ©pendances nÃ©cessaires :
   ```bash
   pip install -r requirements.txt


## Screen pour freamwork complet par streamlit 
<img width="1203" height="697" alt="screen-app1" src="https://github.com/user-attachments/assets/278b4e18-fcf8-4028-b533-849b51853834" />

<img width="1202" height="685" alt="Screen-app2" src="https://github.com/user-attachments/assets/7588dcb0-95cf-4d87-b4d5-2d601a907290" />

<img width="1190" height="647" alt="screen-app3" src="https://github.com/user-attachments/assets/3d3a7b5b-6bab-4406-a85e-093d2613a0ab" />

<img width="1202" height="632" alt="screen-app4" src="https://github.com/user-attachments/assets/271cdfe5-c364-4144-8e86-d1e83776578c" />

<img width="1205" height="672" alt="screen-app5" src="https://github.com/user-attachments/assets/16ba5a4d-7977-4707-8658-2f4976bdd434" />

<img width="1195" height="653" alt="screen-app6" src="https://github.com/user-attachments/assets/9d97b84f-4ffd-41e0-844c-5019cc6c2b09" />

<img width="1201" height="672" alt="screen-app7" src="https://github.com/user-attachments/assets/22548367-b651-44f0-aef7-aea43a78e852" />

    - remarque : video freamwork_streamlit (1).mp4 contient l'app complet 



## ğŸ“ License

Educational use only. Respect robots.txt and terms of service.
